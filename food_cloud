#!/usr/bin/env python
import pandas as pd
from wordcloud import WordCloud, STOPWORDS
import matplotlib.pyplot as plt
from geocoder.location import Location

import os
import re
import sys
import time
import urllib.request

DEFAULT_REFRESH = 24 * 60 * 60

def print_msg(message, **kwargs):
    print(message, file=sys.stderr, **kwargs)

def refresh_data(url, filename, refresh_interval = DEFAULT_REFRESH):
    target_path = os.path.join(os.getcwd(), filename)
    last_modified = os.path.getmtime(target_path) if os.path.exists(target_path) else 0
    if refresh_interval < time.time() - last_modified:
        print_msg(f"Downloading from {url}...")
        urllib.request.urlretrieve(url, target_path)
        print_msg("done")
    else:
        print_msg(f"Using cached data at {target_path}")
    return target_path

def load_dataframe(url, filename, refresh_interval = DEFAULT_REFRESH):
    path = refresh_data(url, filename, refresh_interval)
    df = pd.read_csv(path, parse_dates=["starttime","endtime"], date_format="%I%p")
    return df

def frequent_words(wordlist, top):
    counts = {}
    for word in wordlist:
        if word in counts:
            counts[word] += 1
        else:
            counts[word] = 1
    counted_words = sorted([(count, word) for (word,count) in counts.items()], reverse=True)
    return [word for (count, word) in counted_words[0:top]]

if __name__ == '__main__':
    df = load_dataframe("https://data.sfgov.org/api/views/jjew-r69b/rows.csv", "schedule.csv")
    epoch_t = time.time()
    t = time.localtime(epoch_t)
    midnight = int(time.mktime((t.tm_year, t.tm_mon, t.tm_mday, 0, 0, 0, 0, 0, -1)))
    nowtime = int(epoch_t- midnight)
    weekday = t.tm_wday

    stop_words = set(STOPWORDS)
    all_words = []
    for truck_foods in df['optionaltext']:
        try:
            food_words = re.split("[^\w]+", truck_foods.lower())
            all_words += [word for word in food_words if word not in stop_words]
        except:
            pass

    #it turns out there are a lot of boring words, so lets kill the most frequent ones
    frequent = set(frequent_words(all_words, top=75))
    foods = " ".join([word for word in all_words if word not in frequent])

    wordcloud = WordCloud(width=800, height=600, background_color="white").generate(foods)

    plt.figure(figsize=(8, 6))
    plt.imshow(wordcloud, interpolation='bilinear')
    plt.axis("off")
    plt.title("Word Cloud from Text Data")
    plt.show()
